{
  "SA-models": {
    "LF_DNN": {
      "title": "Benchmarking Multimodal Sentiment Analysis",
      "paper_url": "https://link.springer.com/chapter/10.1007/978-3-319-77116-8_13",
      "citation": "",
      "description": "Late Fusion Network."
    },
    "TFN": {
      "title": "Tensor Fusion Network for Multimodal Sentiment Analysis",
      "paper_url": "https://www.aclweb.org/anthology/D17-1115.pdf",
      "citation": "",
      "description": "Tensor Fusion Network."
    },
    "EF_LSTM": {
      "title": "Recognizing Emotions in Video Using Multimodal DNN Feature Fusion",
      "paper_url": "https://www.aclweb.org/anthology/W18-3302.pdf",
      "citation": "",
      "description": "Early Fusion Network Using LSTM."
    },
    "LMF": {
      "title": "Efficient Low-rank Multimodal Fusion with Modality-Specific Factors",
      "paper_url": "https://www.aclweb.org/anthology/P18-1209.pdf",
      "citation": "",
      "description": "Low-rank Memory Fusion Network."
    },
    "MFN": {
      "title": "Memory Fusion Network for Multi-View Sequential Learning",
      "paper_url": "https://arxiv.org/abs/1802.00927",
      "citation": "",
      "description": "Memory Fusion Network."
    },
    "Graph_MFN": {
      "title": "Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph",
      "paper_url": "https://www.aclweb.org/anthology/P18-1208.pdf",
      "citation": "",
      "description": "Dynamic Fusin Graph after Memory Fusion Network."
    },
    "MFM": {
      "title": "Memory fusion network for multiview sequential learning",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/12021",
      "citation": "",
      "description": "Memory fusion network for multiview sequential learning"
    },
    "MulT": {
      "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences",
      "paper_url": "https://github.com/yaohungt/Multimodal-Transformer",
      "citation": "",
      "description": "Multimodal Transformer for Unaligned Multimodal Language Sequences"
    },

    "MTFN": {
      "title": "CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality",
      "paper_url": "https://www.aclweb.org/anthology/2020.acl-main.343.pdf",
      "citation": "",
      "description": "Multi-task Multimodal Learning Framework for TFN."
    },
    "MLF_DNN": {
      "title": "CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality",
      "paper_url": "https://www.aclweb.org/anthology/2020.acl-main.343.pdf",
      "citation": "",
      "description": "Multi-task Multimodal Learning Framework for LF_DNN."
    },
    "MLMF": {
      "title": "CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality",
      "paper_url": "https://www.aclweb.org/anthology/2020.acl-main.343.pdf",
      "citation": "",
      "description": "Multi-task Multimodal Learning Framework for LMF."
    },
    "ALMT": {
      "title": "Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis",
      "paper_url": "https://aclanthology.org/2023.emnlp-main.49",
      "citation": "",
      "description": "Multi-task Multimodal Learning Framework for ALMT."
    }
  }
  "SR-models"{
  "HMM_GMM": {
    "title": "Hidden Markov Model and Gaussian Mixture Model for Speech Recognition",
    "paper_url": "https://www.researchgate.net/publication/292496357_Hidden_Markov_modelGaussian_mixture_models_HMMGMM_based_voice_command_system_A_way_to_improve_the_control_of_remotely_operated_robot_arm_TR45",
    "citation": "",
    "description": "A traditional approach combining Hidden Markov Models (HMM) and Gaussian Mixture Models (GMM) for automatic speech recognition."
  },
  "SVM": {
    "title": "Speech Recognition using Support Vector Machines",
    "paper_url": "https://papers.nips.cc/paper_files/paper/2001/file/d8330f857a17c53d217014ee776bfd50-Paper.pdf",
    "citation": "",
    "description": "Application of Support Vector Machines (SVM) in the field of speech recognition."
  },
  "Whisper_base": {
    "title": "Robust Speech Recognition via Large-Scale Weak Supervision",
    "paper_url": "https://cdn.openai.com/papers/whisper.pdf",
    "citation": "",
    "description": "Whisper is a general-purpose speech recognition model trained on a large dataset of diverse audio, capable of multilingual speech recognition and translation."
  },
  "Wav2Vec_2.0": {
    "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
    "paper_url": "https://arxiv.org/abs/2006.11477",
    "citation": "",
    "description": "A framework for self-supervised learning of speech representations, achieving state-of-the-art results in speech recognition tasks."
  },
  "Paraformer": {
    "title": "Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition",
    "paper_url": "https://arxiv.org/abs/2206.08317",
    "citation": "",
    "description": "A non-autoregressive transformer model designed for fast and accurate end-to-end speech recognition."
  }
}
  
}
